{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dgl\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from scipy import io as sio\n",
    "from scipy.sparse import coo_matrix\n",
    "from dgl.sampling import sample_neighbors\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './'\n",
    "\n",
    "data_config = {\n",
    "    'data_path': os.path.join(config_path, 'data'),\n",
    "    'dataset': 'ACM', # ACM, DBLP, IMDB, AIFB\n",
    "    'data_name': 'ACM.mat', # ACM.mat, DBLP.mat, IMDB.mat, AIFB.mat\n",
    "    'primary_type': 'p', # p, a, m, Personen            # primary node type\n",
    "    'task': ['CF', 'CL'],\n",
    "    'K_length': 4, # Context path length K\n",
    "    'resample': False, # Whether resample the training and testing dataset\n",
    "    'random_seed': 123,\n",
    "    'test_ratio': 0.8\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'primary_type': data_config['primary_type'],\n",
    "    'auxiliary_embedding': 'non_linear',  # auxiliary embedding generating method: non_linear, linear, emb\n",
    "    'K_length': data_config['K_length'],\n",
    "    'embedding_dim': 128,\n",
    "    'in_dim': 128,\n",
    "    'out_dim': 128,\n",
    "    'num_heads': 8,\n",
    "    'merge': 'linear',  # Multi head Attention merge method: linear, mean, stack\n",
    "    'g_agg_type': 'mean',  # Graph representation encoder: mean, sum\n",
    "    'drop_out': 0.3,\n",
    "    'cgnn_non_linear': True,  # Enable non linear activation function for CGNN\n",
    "    'multi_attn_linear': False,  # Enable atten K/Q-linear for each type\n",
    "    'graph_attention': True,\n",
    "    'kq_linear_out_dim': 128,\n",
    "    'path_attention': False,  # Enable Context path attention\n",
    "    'c_linear_out_dim': 8,\n",
    "    'enable_bilinear': False,  # Enable Bilinear for context attention\n",
    "    'gru': True,\n",
    "    'add_init': False\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'continue': False,\n",
    "    'lr': 0.05,\n",
    "    'l2': 0,\n",
    "    'factor': 0.2,\n",
    "    'total_epoch': 10000000,\n",
    "    'batch_size': 1024 * 20,\n",
    "    'pos_num_for_each_hop': [20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
    "    'neg_num_for_each_hop': [3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
    "    'sample_workers': 8,\n",
    "    'patience': 15,\n",
    "    'checkpoint_path': os.path.join(config_path, 'checkpoint', data_config['dataset'])\n",
    "}\n",
    "\n",
    "evaluate_config = {\n",
    "    'method': 'LR',\n",
    "    'save_heat_map': True,\n",
    "    'result_path': os.path.join('result', data_config['dataset']),\n",
    "    'random_state': 123,\n",
    "    'max_iter': 500,\n",
    "    'n_jobs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgesDataset(Dataset):\n",
    "    def __init__(self, hg, pos_sample_num, neg_sample_num):\n",
    "        self.hg = hg\n",
    "        self.pos_sample_num = pos_sample_num\n",
    "        self.neg_sample_num = neg_sample_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.hg.number_of_nodes()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pos_graph = sample_neighbors(self.hg, [idx], self.pos_sample_num, edge_dir='out')\n",
    "        pos_src, pos_dst = pos_graph.edges()\n",
    "        neg_src = pos_src.repeat(self.neg_sample_num)\n",
    "        neg_dst = torch.randint(0, self.hg.number_of_nodes(), neg_src.shape, dtype=torch.long)\n",
    "        return pos_src, pos_dst, neg_src, neg_dst\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batches):\n",
    "        pos_src = []\n",
    "        pos_dst = []\n",
    "        neg_src = []\n",
    "        neg_dst = []\n",
    "        for item in batches:\n",
    "            pos_src.append(item[0])\n",
    "            pos_dst.append(item[1])\n",
    "            neg_src.append(item[2])\n",
    "            neg_dst.append(item[3])\n",
    "        return torch.cat(pos_src), torch.cat(pos_dst), torch.cat(neg_src), torch.cat(neg_dst)\n",
    "\n",
    "class GraphDataLoader(object):\n",
    "    def __init__(self, data_config, remove_self_loop):\n",
    "        self.data_config = data_config\n",
    "        self.base_data_path = os.path.join(data_config['data_path'], data_config['dataset'])\n",
    "        self.data_path = os.path.join(data_config['data_path'], data_config['dataset'], data_config['data_name'])\n",
    "        self.train_data_path = os.path.join(data_config['data_path'], data_config['dataset'], 'train_data')\n",
    "        if not os.path.exists(self.train_data_path):\n",
    "            os.mkdir((self.train_data_path))\n",
    "        self.k_hop_graph_path = os.path.join(self.train_data_path, 'graph')\n",
    "        if not os.path.exists(self.k_hop_graph_path):\n",
    "            os.mkdir(self.k_hop_graph_path)\n",
    "\n",
    "    def load_raw_matrix(self):\n",
    "        raise NotImplementedError(\"Not Implement load_raw_matrix\")\n",
    "\n",
    "    def load_k_hop_train_data(self):\n",
    "        raise NotImplementedError(\"Not Implement load_k_hop_train_data method\")\n",
    "\n",
    "    def load_classification_data(self):\n",
    "        raise NotImplementedError(\"Not Implement load_classification_data method\")\n",
    "\n",
    "    def load_links_prediction_data(self):\n",
    "        raise NotImplementedError(\"Not Implement load_links_prediction_data method\")\n",
    "\n",
    "    def _load_k_hop_graph(self, hg, k, primary_type):\n",
    "        '''\n",
    "        Return k hop neighbors graph\n",
    "        :param hg: DGLHeteroGraph\n",
    "        :param k: hop neighbors\n",
    "        :param primary_type: primary_type\n",
    "        :return: k-hop graph of primary type graph, DGLHeteroGraph\n",
    "        '''\n",
    "        print('Process: {} hop graph'.format(k))\n",
    "        k_hop_graph_path = os.path.join(self.k_hop_graph_path,\n",
    "                                        '{}_{}_hop_graph.pkl'.format(primary_type, k))\n",
    "        if not os.path.exists(k_hop_graph_path):\n",
    "            ntype = hg.ntypes\n",
    "            primary_type_id = ntype.index(primary_type)\n",
    "            homo_g = dgl.to_homo(hg)\n",
    "            p_nodes_id = homo_g.filter_nodes(\n",
    "                lambda nodes: (nodes.data['_TYPE'] == primary_type_id))  # Find the primary nodes ID\n",
    "            min_p = torch.min(p_nodes_id).item()\n",
    "            max_p = torch.max(p_nodes_id).item()\n",
    "            raw_adj = homo_g.adjacency_matrix()  # It is a square matrix\n",
    "            # Speed up with torch\n",
    "            raw_adj = raw_adj.to_dense().float()\n",
    "            adj_k = torch.matrix_power(raw_adj, k)  # K-hop neighbors\n",
    "            p_adj = adj_k[min_p:max_p, min_p:max_p].cpu()  # Get primary sub graph\n",
    "            row, col = torch.nonzero(p_adj, as_tuple=True)\n",
    "            p_g = dgl.graph((row, col))\n",
    "            with open(k_hop_graph_path, 'wb') as f:\n",
    "                pickle.dump(p_g, f, protocol=4)\n",
    "        else:\n",
    "            with open(k_hop_graph_path, 'rb') as f:\n",
    "                p_g = pickle.load(f)\n",
    "        return p_g\n",
    "\n",
    "    def load_train_k_context_edges(self, hg, K, primary_type, pos_num_for_each_hop, neg_num_for_each_hop):\n",
    "        edges_data_dict = {}\n",
    "        for k in range(1, K + 2):\n",
    "            k_hop_primary_graph = self._load_k_hop_graph(hg, k, primary_type)\n",
    "            k_hop_edge = EdgesDataset(k_hop_primary_graph, pos_num_for_each_hop[k], neg_num_for_each_hop[k])\n",
    "            edges_data_dict[k] = k_hop_edge\n",
    "        return edges_data_dict\n",
    "\n",
    "class ACMDataLoader(GraphDataLoader):\n",
    "    def __init__(self, data_config, remote_self_loop):\n",
    "        super(ACMDataLoader, self).__init__(data_config, remote_self_loop)\n",
    "\n",
    "        self.heter_graph, self.raw_matrix = self.load_raw_matrix()\n",
    "\n",
    "    def load_raw_matrix(self):\n",
    "        data = sio.loadmat(self.data_path)\n",
    "        '''\n",
    "        ['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n",
    "        P: Paper\n",
    "        Aï¼šAuthor\n",
    "        F: Facility\n",
    "        C: Conference\n",
    "        L: Subject\n",
    "        '''\n",
    "\n",
    "        # EDGES\n",
    "        p_vs_l = data['PvsL']  # paper-Subject\n",
    "        p_vs_p = data['PvsP']  # paper-paper\n",
    "        p_vs_a = data['PvsA']  # paper-author\n",
    "        a_vs_f = data['AvsF']  # author-facility\n",
    "\n",
    "        # src_type, edge_type, dst_type\n",
    "        hg = dgl.heterograph({\n",
    "            ('p', 'pa', 'a'): p_vs_a,\n",
    "            ('a', 'ap', 'p'): p_vs_a.transpose(),\n",
    "            ('p', 'pp', 'p'): p_vs_p,  # P cite P\n",
    "            ('p', 'ps', 's'): p_vs_l,\n",
    "            ('s', 'sp', 'p'): p_vs_l.transpose(),\n",
    "            ('a', 'af', 'f'): a_vs_f,\n",
    "            ('f', 'fa', 'a'): a_vs_f.transpose(),\n",
    "        })\n",
    "\n",
    "        return hg, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = ACMDataLoader(data_config, remote_self_loop=False)\n",
    "hg = dataloader.heter_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 1 hop graph\n",
      "Process: 2 hop graph\n",
      "Process: 3 hop graph\n",
      "Process: 4 hop graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\.conda\\envs\\torch111\\lib\\site-packages\\dgl\\base.py:25: UserWarning: Currently adjacency_matrix() returns a matrix with destination as rows by default.  In 0.5 the result will have source as rows (i.e. transpose=True)\n",
      "  warnings.warn(msg, warn_type)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4046740996 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\ADL projeccts\\Community Detection\\community-detection.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m edges_data_dict \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39;49mload_train_k_context_edges(hg, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                         data_config[\u001b[39m'\u001b[39;49m\u001b[39mK_length\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                         data_config[\u001b[39m'\u001b[39;49m\u001b[39mprimary_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                         train_config[\u001b[39m'\u001b[39;49m\u001b[39mpos_num_for_each_hop\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                         train_config[\u001b[39m'\u001b[39;49m\u001b[39mneg_num_for_each_hop\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                                         )\n",
      "\u001b[1;32mc:\\Projects\\ADL projeccts\\Community Detection\\community-detection.ipynb Cell 5\u001b[0m in \u001b[0;36mGraphDataLoader.load_train_k_context_edges\u001b[1;34m(self, hg, K, primary_type, pos_num_for_each_hop, neg_num_for_each_hop)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m edges_data_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, K \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     k_hop_primary_graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_k_hop_graph(hg, k, primary_type)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     k_hop_edge \u001b[39m=\u001b[39m EdgesDataset(k_hop_primary_graph, pos_num_for_each_hop[k], neg_num_for_each_hop[k])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     edges_data_dict[k] \u001b[39m=\u001b[39m k_hop_edge\n",
      "\u001b[1;32mc:\\Projects\\ADL projeccts\\Community Detection\\community-detection.ipynb Cell 5\u001b[0m in \u001b[0;36mGraphDataLoader._load_k_hop_graph\u001b[1;34m(self, hg, k, primary_type)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# Speed up with torch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m raw_adj \u001b[39m=\u001b[39m raw_adj\u001b[39m.\u001b[39mto_dense()\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m adj_k \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatrix_power(raw_adj, k)  \u001b[39m# K-hop neighbors\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m p_adj \u001b[39m=\u001b[39m adj_k[min_p:max_p, min_p:max_p]\u001b[39m.\u001b[39mcpu()  \u001b[39m# Get primary sub graph\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/ADL%20projeccts/Community%20Detection/community-detection.ipynb#X11sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m row, col \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnonzero(p_adj, as_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4046740996 bytes."
     ]
    }
   ],
   "source": [
    "edges_data_dict = dataloader.load_train_k_context_edges(hg, \n",
    "                                                        data_config['K_length'],\n",
    "                                                        data_config['primary_type'],\n",
    "                                                        train_config['pos_num_for_each_hop'],\n",
    "                                                        train_config['neg_num_for_each_hop']\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch111')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38d61779fb8a2d479ca2bc1a752fe475f56efe678dc670cf5ac86029018bbcc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
